{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rc2_depression.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FC5k7mN0_Zr",
        "colab_type": "text"
      },
      "source": [
        "Copyright 2019 [BIG CHENG](mailto:name@email.com)\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2s_P6kyrWeAR",
        "colab_type": "text"
      },
      "source": [
        "#Deep learning based facial emotion recognition and emotion drivened reinforcement learning agent\n",
        "Lots of people living in modern world feel unhappy. Can you image, \"Globally, more than 300 million people of all ages suffer from depression.\" (from [WHO/depression](https://www.who.int/news-room/fact-sheets/detail/depression))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfsOgW70nFUf",
        "colab_type": "text"
      },
      "source": [
        "#Install Tensorflow 2.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGxPNJHjujp4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0-alpha0\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBnBxjUAqk_H",
        "colab_type": "text"
      },
      "source": [
        "#Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku9IkkGupn8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image, display\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evB1z4UGrGMe",
        "colab_type": "text"
      },
      "source": [
        "#Import Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGjvT-UYqbxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## using google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "#Copy dataset here ...\n",
        "#One simple option is Kaggle/FER2013 \n",
        "\n",
        "#inspect some data\n",
        "!ls Training | head\n",
        "display(Image('Training/i00000_e0_t0.png'))\n",
        "display(Image('Training/i00002_e2_t0.png'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2l_oiX8uR8g",
        "colab_type": "text"
      },
      "source": [
        "#Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3crA9kIcuXY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_SIZE = 96\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def fn_mapping(fname, label):\n",
        "  image_decoded = tf.image.decode_jpeg(tf.io.read_file(fname))\n",
        "  image_normalized = (tf.cast(image_decoded, tf.float32)/127.5) - 1\n",
        "  image_resized = tf.image.resize(image_normalized, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "  image_concated = tf.concat([image_resized, image_resized, image_resized], 2)\n",
        "  return image_concated, label\n",
        "\n",
        "#fnames_train = [os.path.join(dir_name, fname) for fname in filenames]\n",
        "#lables_train = ...\n",
        "#fnames_val = [os.path.join(dir_name, fname) for fname in filenames]\n",
        "#lables_val = ...\n",
        "data2train = tf.data.Dataset.from_tensor_slices((tf.constant(fnames_train), tf.constant(labels_train))).map(fn_mapping).shuffle(buffer_size=10000).batch(BATCH_SIZE)\n",
        "data2val = tf.data.Dataset.from_tensor_slices((tf.constant(fnames_val), tf.constant(labels_val))).map(fn_mapping).batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYsiDPIWsdPe",
        "colab_type": "text"
      },
      "source": [
        "#Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-AsJ7lurjWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Base model - MobileNetV2\n",
        "IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False, \n",
        "                                               weights='imagenet')\n",
        "maxpool_layer = tf.keras.layers.GlobalMaxPooling2D()\n",
        "prediction_layer = tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    maxpool_layer,\n",
        "    prediction_layer\n",
        "])\n",
        "\n",
        "learning_rate = 0.0001\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=learning_rate),\n",
        "             loss='binary_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaeK0rkjw0nY",
        "colab_type": "text"
      },
      "source": [
        "#Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ejpc8qGFw6op",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs = 10\n",
        "steps_per_epoch = round(len(labels_train))//BATCH_SIZE\n",
        "validation_steps = 20\n",
        "\n",
        "history = model.fit(data2train.repeat(),\n",
        "                    epochs=num_epochs,\n",
        "                    steps_per_epoch = steps_per_epoch,\n",
        "                    validation_data=data2val.repeat(), \n",
        "                    validation_steps=validation_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNGCyjmPysT7",
        "colab_type": "text"
      },
      "source": [
        "#Recognize Emotion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqWGR6qMy26A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# image from camera, preprocessed and resized to IMAGE_SIZE\n",
        "# imgs2pred = np.zeros((num_pred, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "# ...\n",
        "\n",
        "cls = model.predict(imgs2pred)\n",
        "\n",
        "for i in range(num_pred):\n",
        "  print (cls[i])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}